{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import json\n",
    "with open('data.json', 'r') as file:\n",
    "    data = file.read().replace('\\xa0', ' ')\n",
    "    \n",
    "data=json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic json transformations to df\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.json_normalize(data).transpose()\n",
    "\n",
    "df=df[df.index.str.contains('children')]\n",
    "df=df.reset_index()\n",
    "df.columns=['big_category','nice']\n",
    "\n",
    "def rep(x):\n",
    "    return x.split('.')[0]\n",
    "df.big_category=df.big_category.apply(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand the jsons - one layer further\n",
    "df1=pd.concat([df.big_category, pd.json_normalize(df.nice)],axis=1)\n",
    "\n",
    "df1.index=df1.big_category\n",
    "df1.drop(columns='big_category',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract info from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our uncleaned corpus to list of jsons\n",
    "import numpy as np\n",
    "listy=df1.values.reshape(-1)\n",
    "listy=listy[listy != np.array(None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand the list of jsons 2 layers deeper\n",
    "pre_final_corpus = dict()\n",
    "\n",
    "for i in listy:\n",
    "    yeboy=pd.json_normalize(i,'children', meta='title',meta_prefix='ll_')\n",
    "    for j in yeboy.title:\n",
    "        # dict of jsons\n",
    "        pre_final_corpus[yeboy[yeboy.title==j].title.values[0]] = yeboy[yeboy.title==j].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>children</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>ob_class</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Ride-on sweeper</td>\n",
       "      <td>Ride-on sweeper</td>\n",
       "      <td>Ride-on sweeper Ride-on sweeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manufacturer</td>\n",
       "      <td>[{'title': 'Draper (8)'}, {'title': 'Kaiser+Kr...</td>\n",
       "      <td>Street broom</td>\n",
       "      <td>Street broom</td>\n",
       "      <td>Manufacturer [{'title': 'Draper (8)'}, {'title...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Broom width</td>\n",
       "      <td>[{'title': '30 cm (8)'}, {'title': '33 cm (4)'...</td>\n",
       "      <td>Street broom</td>\n",
       "      <td>Street broom</td>\n",
       "      <td>Broom width [{'title': '30 cm (8)'}, {'title':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bristle material</td>\n",
       "      <td>[{'title': 'Coco (7)'}, {'title': 'Piassava (1...</td>\n",
       "      <td>Street broom</td>\n",
       "      <td>Street broom</td>\n",
       "      <td>Bristle material [{'title': 'Coco (7)'}, {'tit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Handle system</td>\n",
       "      <td>[{'title': 'Thread (2)'}, {'title': 'n/a (48)'}]</td>\n",
       "      <td>Street broom</td>\n",
       "      <td>Street broom</td>\n",
       "      <td>Handle system [{'title': 'Thread (2)'}, {'titl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title                                           children  \\\n",
       "0                                                                        \n",
       "0      Manufacturer  [{'title': 'Draper (8)'}, {'title': 'Kaiser+Kr...   \n",
       "1       Broom width  [{'title': '30 cm (8)'}, {'title': '33 cm (4)'...   \n",
       "2  Bristle material  [{'title': 'Coco (7)'}, {'title': 'Piassava (1...   \n",
       "3     Handle system   [{'title': 'Thread (2)'}, {'title': 'n/a (48)'}]   \n",
       "\n",
       "         sub_title         ob_class  \\\n",
       "0  Ride-on sweeper  Ride-on sweeper   \n",
       "0     Street broom     Street broom   \n",
       "1     Street broom     Street broom   \n",
       "2     Street broom     Street broom   \n",
       "3     Street broom     Street broom   \n",
       "\n",
       "                                              corpus  \n",
       "0                    Ride-on sweeper Ride-on sweeper  \n",
       "0  Manufacturer [{'title': 'Draper (8)'}, {'title...  \n",
       "1  Broom width [{'title': '30 cm (8)'}, {'title':...  \n",
       "2  Bristle material [{'title': 'Coco (7)'}, {'tit...  \n",
       "3  Handle system [{'title': 'Thread (2)'}, {'titl...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list-catalouge will be used to enrich the user query results with parameters\n",
    "product_info = []\n",
    "\n",
    "# extract parameters for each (sub)category\n",
    "for i in pre_final_corpus.keys():\n",
    "\n",
    "    try:\n",
    "        # we deal with the hirerachy granularity (depth)\n",
    "        if 'tag' in str(pre_final_corpus[i][0]):\n",
    "\n",
    "            objects = pre_final_corpus[i][0][3]\n",
    "            bff=pd.json_normalize(pre_final_corpus[i][0][3], 'tags', meta='title', meta_prefix='sub_')\n",
    "\n",
    "            # remove empty rows\n",
    "            bff=bff[bff.children.apply(len)>0]\n",
    "\n",
    "            # add higher level item categories\n",
    "            bff['ob_class']=i\n",
    "\n",
    "            # add to list\n",
    "            product_info.append(bff)\n",
    "\n",
    "        else:\n",
    "            objects = pre_final_corpus[i][0][2]\n",
    "\n",
    "            # extract from json\n",
    "            bff=pd.json_normalize(objects)\n",
    "\n",
    "            # remove empty rows\n",
    "            bff=bff[bff.children.apply(len)>0]\n",
    "\n",
    "            # add higher level item categories\n",
    "            bff['sub_title']=i\n",
    "            bff['ob_class']=i\n",
    "\n",
    "            # add to list\n",
    "            product_info.append(bff)\n",
    "    except:\n",
    "        # add to dict\n",
    "        product_info.append(pd.DataFrame({'title':[''], 'children':[''], \n",
    "                                            'sub_title':[i], 'ob_class':[i]}))\n",
    "    # drop the interm. df\n",
    "    bff=None\n",
    "    \n",
    "# final dataframe with all the lists\n",
    "product_info = pd.concat(product_info)\n",
    "product_info.loc[product_info.title.apply(str).str.contains('Manufacturer'), 'title']='Manufacturer'\n",
    "\n",
    "# concat columns (str) to construct the bag of words\n",
    "product_info['corpus']=product_info.title + ' ' + product_info.children.apply(str)\\\n",
    "                        + ' ' + product_info.sub_title  + ' ' + product_info.ob_class\n",
    "\n",
    "product_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP: data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs and prepare transformators for data preprossessing\n",
    "import string\n",
    "from string import digits\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize, pos_tag\n",
    "# import re\n",
    "# import nltk\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['manufacturer', 'cm', 'l', 'm', 'kg', 'g', 'w', 'r', 'ø',\n",
    "                    'brand', 'new', 'something','tag', 'description','material','width','weight',\n",
    "                    'volume','na', 'content', 'no','mm', 'piece', 'ml', 'µf', 'µh', 'µm', 'μf'])\n",
    "\n",
    "spcial_char_map = {ord('ä'):'a', ord('ü'):'u', ord('ö'):'o', ord('ß'):'s'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mega-function that cleans up the corpus: tokenizes, lemmatizes, removes verbs, etc.\n",
    "\n",
    "def krasavchik(jj):\n",
    "\n",
    "    #safe the category name\n",
    "    if \"'title':\" in str(jj):\n",
    "        \n",
    "        # collapse to string\n",
    "        jj=str(jj).replace(\"'children':\",'').replace(\"'title':\",'').replace(\"_\",' ')\n",
    "        \n",
    "    else:\n",
    "        jj=str(jj).replace(\"_\",' ')\n",
    "        \n",
    "    #remove parentheces\n",
    "    # jj=re.sub(r'\\([^)]*\\)', '', jj)\n",
    "\n",
    "    #remove punctuation and to lower\n",
    "    jj=jj.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "    #remove numeric values\n",
    "    jj = jj.translate(str.maketrans('', '', digits))\n",
    "\n",
    "    #replace umlauds with english alternatives\n",
    "    jj=jj.translate(spcial_char_map)\n",
    "\n",
    "    #tokenize\n",
    "    jj=word_tokenize(jj)\n",
    "\n",
    "    #lemmatize\n",
    "    jj=list(map(lemmatizer.lemmatize, jj))\n",
    "\n",
    "    #REMOVE verbs\n",
    "    jj=pd.DataFrame(pos_tag(jj))\n",
    "    jj.columns=['words','part']\n",
    "    jj=jj[~jj.part.isin(['VBD','VBN','VBP','VBZ'])]\n",
    "\n",
    "    #remove empty values\n",
    "    # jj=list(filter(('').__ne__, jj))\n",
    "\n",
    "    #remove stopwords and duplicates (we will not account for frequencies due to nature of quering)\n",
    "    jj=jj.drop_duplicates(subset=['words'])\n",
    "    jj=jj[~jj.words.isin(stop_words)].words.tolist()\n",
    "\n",
    "    return jj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # categories that we have \n",
    "# categories = krasavchik(final.names.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manufacturers catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>ob_class</th>\n",
       "      <th>corpus</th>\n",
       "      <th>manufacturers</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'title': 'Draper (8)'}, {'title': 'Kaiser+Kr...</td>\n",
       "      <td>Street broom</td>\n",
       "      <td>Street broom</td>\n",
       "      <td>Manufacturer [{'title': 'Draper (8)'}, {'title...</td>\n",
       "      <td>[Draper, KaiserKraft, RS Pro, Sealey, Vikan, W...</td>\n",
       "      <td>[draper, kaiserkraft, pro, sealey, vikan, wurth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'title': 'Apple (8)'}, {'title': 'Black &amp; De...</td>\n",
       "      <td>Cordless vacuum cleaner</td>\n",
       "      <td>Vacuum cleaner</td>\n",
       "      <td>Manufacturer [{'title': 'Apple (8)'}, {'title'...</td>\n",
       "      <td>[Apple, Black Decker, Kärcher, Makita, Milwauk...</td>\n",
       "      <td>[apple, black, decker, karcher, makita, milwau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[{'title': 'Draper (19)'}, {'title': 'Electros...</td>\n",
       "      <td>Bagless vacuum cleaner</td>\n",
       "      <td>Vacuum cleaner</td>\n",
       "      <td>Manufacturer [{'title': 'Draper (19)'}, {'titl...</td>\n",
       "      <td>[Draper, Electrostar, Karcher, Kärcher, Sealey...</td>\n",
       "      <td>[draper, electrostar, karcher, sealey, slingsby]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>[{'title': 'Draper (17)'}, {'title': 'Electros...</td>\n",
       "      <td>Floor vacuum cleaner</td>\n",
       "      <td>Vacuum cleaner</td>\n",
       "      <td>Manufacturer [{'title': 'Draper (17)'}, {'titl...</td>\n",
       "      <td>[Draper, Electrostar, Karcher, Kärcher, Sealey...</td>\n",
       "      <td>[draper, electrostar, karcher, sealey, slingsby]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[{'title': 'Bosch (1)'}, {'title': 'Coreparts ...</td>\n",
       "      <td>Upright vacuum cleaner</td>\n",
       "      <td>Vacuum cleaner</td>\n",
       "      <td>Manufacturer [{'title': 'Bosch (1)'}, {'title'...</td>\n",
       "      <td>[Bosch, Coreparts, DEERMA Malaysia, Karcher, K...</td>\n",
       "      <td>[bosch, coreparts, malaysia, karcher, slingsby]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             children  \\\n",
       "0   [{'title': 'Draper (8)'}, {'title': 'Kaiser+Kr...   \n",
       "0   [{'title': 'Apple (8)'}, {'title': 'Black & De...   \n",
       "70  [{'title': 'Draper (19)'}, {'title': 'Electros...   \n",
       "74  [{'title': 'Draper (17)'}, {'title': 'Electros...   \n",
       "78  [{'title': 'Bosch (1)'}, {'title': 'Coreparts ...   \n",
       "\n",
       "                  sub_title        ob_class  \\\n",
       "0              Street broom    Street broom   \n",
       "0   Cordless vacuum cleaner  Vacuum cleaner   \n",
       "70   Bagless vacuum cleaner  Vacuum cleaner   \n",
       "74     Floor vacuum cleaner  Vacuum cleaner   \n",
       "78   Upright vacuum cleaner  Vacuum cleaner   \n",
       "\n",
       "                                               corpus  \\\n",
       "0   Manufacturer [{'title': 'Draper (8)'}, {'title...   \n",
       "0   Manufacturer [{'title': 'Apple (8)'}, {'title'...   \n",
       "70  Manufacturer [{'title': 'Draper (19)'}, {'titl...   \n",
       "74  Manufacturer [{'title': 'Draper (17)'}, {'titl...   \n",
       "78  Manufacturer [{'title': 'Bosch (1)'}, {'title'...   \n",
       "\n",
       "                                        manufacturers  \\\n",
       "0   [Draper, KaiserKraft, RS Pro, Sealey, Vikan, W...   \n",
       "0   [Apple, Black Decker, Kärcher, Makita, Milwauk...   \n",
       "70  [Draper, Electrostar, Karcher, Kärcher, Sealey...   \n",
       "74  [Draper, Electrostar, Karcher, Kärcher, Sealey...   \n",
       "78  [Bosch, Coreparts, DEERMA Malaysia, Karcher, K...   \n",
       "\n",
       "                                              cleaned  \n",
       "0    [draper, kaiserkraft, pro, sealey, vikan, wurth]  \n",
       "0   [apple, black, decker, karcher, makita, milwau...  \n",
       "70   [draper, electrostar, karcher, sealey, slingsby]  \n",
       "74   [draper, electrostar, karcher, sealey, slingsby]  \n",
       "78    [bosch, coreparts, malaysia, karcher, slingsby]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get just manufacturers from the catalog\n",
    "manufacturers = product_info[product_info.title.isin(['Manufacturer', None])].drop(columns='title')\n",
    "\n",
    "# get list of manufacturers for each product\n",
    "import re\n",
    "def transformy(jj):\n",
    "    # if no info on manufacturers\n",
    "    if jj is None:\n",
    "        return 'no info on manufacturers'\n",
    "    # collapse to string\n",
    "    jj=str(jj).replace(\"'children':\",'').replace(\"{'title':\",'')\n",
    "    # remove values between parentheces\n",
    "    jj=re.sub(r'\\([^)]*\\)', '', jj)\n",
    "    # remove punctuation\n",
    "    jj=jj.translate(str.maketrans('', '', string.punctuation.replace(',','')))\n",
    "    \n",
    "    # return list of manufacturers in original spelling\n",
    "    return \" \".join(jj.strip().split()).split(' , ')\n",
    "\n",
    "# get list of manufacturers \n",
    "manufacturers['manufacturers']=manufacturers.children.apply(transformy)\n",
    "\n",
    "# cleaned manufacturers \n",
    "manufacturers['cleaned']=manufacturers.children.apply(krasavchik)\n",
    "\n",
    "manufacturers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sip', 'online', 'icidu']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of unique manufacturers in our DB\n",
    "uni_manufacturers = list(set(manufacturers['cleaned'].values.sum()))\n",
    "uni_manufacturers[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cleaning', 'cleansing', 'cleanup']\n"
     ]
    }
   ],
   "source": [
    "# find synonyms for each word in corpus (except brand names!) to enrich the corpus\n",
    "#  - we have no discriptions in original set!\n",
    "def synomizer(x, max_n_synonyms=3, max_depth=4):\n",
    "\n",
    "    # we will not try to find a syns for brand names\n",
    "    if x in uni_manufacturers:\n",
    "        return x\n",
    "    try:\n",
    "        j = wn.synsets(x)[0].lemma_names()\n",
    "\n",
    "        if len(j)==1:\n",
    "            for i in range(1,max_depth):\n",
    "                j = wn.synsets(x)[i].lemma_names()\n",
    "                if len(j)>1:\n",
    "                    break\n",
    "\n",
    "        # # remove words that appear in category names - since we risk bluring the categorization\n",
    "        # j = [e for e in j if e not in categories]    \n",
    "\n",
    "        return krasavchik(j[0:max_n_synonyms] + [x])\n",
    "\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "print(synomizer('cleaning'))\n",
    "\n",
    "# Function to convert list of words to string\n",
    "def listToString(s):\n",
    "    s=str(s)\n",
    "    s=s.translate(str.maketrans('', '', string.punctuation))\n",
    "    return s "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-ear hose clamps</td>\n",
       "      <td>[prevost, hose, clamp, bracket, clamping, range]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10GBase-CX4 network card</td>\n",
       "      <td>[hp, ibm, intel, qnap, acc, spare, part, non, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19 inch document drawer</td>\n",
       "      <td>[allnet, efbelektronik, ic, intracom, intellin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19-inch mounting kit</td>\n",
       "      <td>[apc, cisco, fujitsu, hp, lenovo, vertiv, inch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19-inch power strip</td>\n",
       "      <td>[apc, dell, hp, pduex, power, data, tripp, lit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      names                                             corpus\n",
       "0         1-ear hose clamps   [prevost, hose, clamp, bracket, clamping, range]\n",
       "1  10GBase-CX4 network card  [hp, ibm, intel, qnap, acc, spare, part, non, ...\n",
       "2   19 inch document drawer  [allnet, efbelektronik, ic, intracom, intellin...\n",
       "3      19-inch mounting kit  [apc, cisco, fujitsu, hp, lenovo, vertiv, inch...\n",
       "4       19-inch power strip  [apc, dell, hp, pduex, power, data, tripp, lit..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our corpus\n",
    "\n",
    "final=product_info[['sub_title', 'corpus']].groupby(['sub_title'], as_index = False).agg({'corpus': ' '.join})\n",
    "final.corpus = final.corpus.apply(krasavchik)\n",
    "final.columns=['names', 'corpus']\n",
    "\n",
    "# final=pd.DataFrame({'names': pre_final_corpus.keys(), \n",
    "#                     'corpus' : list(map(krasavchik,pre_final_corpus.items())) } )\n",
    "\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's enrich our corpus with synonyms, since the items have no descriptions to be used in training\n",
    "final['corpus_with_syn']=final.corpus.apply(lambda x: list(map(synomizer,x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add appropriate string for dtm\n",
    "final['corpus_me']=final['corpus_with_syn'].apply(listToString)\n",
    "\n",
    "# remove limited categories\n",
    "final = final[(final.corpus.map(len)>4)|(~final.names.isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>corpus_me</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-ear hose clamps</td>\n",
       "      <td>prevost hosiery hose clamp clinch bracket angl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10GBase-CX4 network card</td>\n",
       "      <td>hp ibm intel qnap acc spare part non ei hw gba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19 inch document drawer</td>\n",
       "      <td>allnet efbelektronik ic intracom intellinet st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19-inch mounting kit</td>\n",
       "      <td>apc cisco fujitsu hp lenovo vertiv inch climb ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19-inch power strip</td>\n",
       "      <td>apc dell hp pduex power data tripp lite inch s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      names                                          corpus_me\n",
       "0         1-ear hose clamps  prevost hosiery hose clamp clinch bracket angl...\n",
       "1  10GBase-CX4 network card  hp ibm intel qnap acc spare part non ei hw gba...\n",
       "2   19 inch document drawer  allnet efbelektronik ic intracom intellinet st...\n",
       "3      19-inch mounting kit  apc cisco fujitsu hp lenovo vertiv inch climb ...\n",
       "4       19-inch power strip  apc dell hp pduex power data tripp lite inch s..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally we are ready to train the classifier!\n",
    "final[['names','corpus_me']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTM - my approach: classifier trained on tf-idf bag of words + fuzzy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abb</th>\n",
       "      <th>abbatron</th>\n",
       "      <th>abc</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>abekp</th>\n",
       "      <th>...</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zincair</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zirconia</th>\n",
       "      <th>zirconium</th>\n",
       "      <th>zmorph</th>\n",
       "      <th>zn</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-ear hose clamps</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10GBase-CX4 network card</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19 inch document drawer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-inch mounting kit</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-inch power strip</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLR wall socket</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XQD card</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xbox</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z rail</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xD-picture card</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 5306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          aa  aaa  aaaa  aaron  ab  abb  abbatron  abc  \\\n",
       "names                                                                    \n",
       "1-ear hose clamps          0    0     0      0   0    0         0    0   \n",
       "10GBase-CX4 network card   0    0     0      0   0    0         0    0   \n",
       "19 inch document drawer    0    0     0      0   0    0         0    0   \n",
       "19-inch mounting kit       0    0     0      0   0    0         0    0   \n",
       "19-inch power strip        0    0     0      0   0    0         0    0   \n",
       "...                       ..  ...   ...    ...  ..  ...       ...  ...   \n",
       "XLR wall socket            0    0     0      0   0    1         0    0   \n",
       "XQD card                   0    0     0      0   0    0         0    0   \n",
       "Xbox                       0    0     0      0   0    0         0    0   \n",
       "Z rail                     0    0     0      0   0    0         0    0   \n",
       "xD-picture card            0    0     0      0   0    0         0    0   \n",
       "\n",
       "                          abdominal  abekp  ...  zinc  zincair  zip  zipper  \\\n",
       "names                                       ...                               \n",
       "1-ear hose clamps                 0      0  ...     0        0    0       0   \n",
       "10GBase-CX4 network card          0      0  ...     0        0    0       0   \n",
       "19 inch document drawer           0      0  ...     0        0    0       0   \n",
       "19-inch mounting kit              0      0  ...     0        0    0       0   \n",
       "19-inch power strip               0      0  ...     0        0    0       0   \n",
       "...                             ...    ...  ...   ...      ...  ...     ...   \n",
       "XLR wall socket                   0      0  ...     0        0    0       0   \n",
       "XQD card                          0      0  ...     0        0    0       0   \n",
       "Xbox                              0      0  ...     0        0    0       0   \n",
       "Z rail                            0      0  ...     0        0    0       0   \n",
       "xD-picture card                   0      0  ...     0        0    0       0   \n",
       "\n",
       "                          zirconia  zirconium  zmorph  zn  zone  zoom  \n",
       "names                                                                  \n",
       "1-ear hose clamps                0          0       0   0     0     0  \n",
       "10GBase-CX4 network card         0          0       0   0     0     0  \n",
       "19 inch document drawer          0          0       0   0     0     0  \n",
       "19-inch mounting kit             0          0       0   0     0     0  \n",
       "19-inch power strip              0          0       0   0     0     0  \n",
       "...                            ...        ...     ...  ..   ...   ...  \n",
       "XLR wall socket                  0          0       0   0     0     0  \n",
       "XQD card                         0          0       0   0     0     0  \n",
       "Xbox                             0          0       0   0     0     0  \n",
       "Z rail                           0          0       0   0     0     0  \n",
       "xD-picture card                  0          0       0   0     0     0  \n",
       "\n",
       "[1644 rows x 5306 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DTM - binary + tfidf (to account for doc size), since we don't care about frequencies - no descriptions!!!\n",
    "from sklearn.feature_extraction.text import CountVectorizer #, TfidfVectorizer\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "count_array = vectorizer.fit_transform(final.corpus_me.tolist()).toarray()\n",
    "dtm = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "# our classes\n",
    "dtm.index=final.names\n",
    "\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train simple Multinomial Naive Bayes classifier - no testing =("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mini_model = MultinomialNB()\n",
    "mini_model.fit(dtm, dtm.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final quering function - our mini item-recomendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pridicts the product category based on query\n",
    "def final_quering(\n",
    "            query, \n",
    "            distince_thresh = 4, # threshold for levinshtein distance\n",
    "            matching_by_first_letter = True, # apply fuzzy matching only for the words that start from the same letter - major efficency boost\n",
    "            certanty_thresh = 0.9, # threshold for our certanty in top 1 prediction - i.e. \"credible region\" we set to 95% from top proba\n",
    "                                   # (set certanty_thresh to None if ypu want to load the top 1 recomendation)\n",
    "            show_more = False # show more info on the results\n",
    "            ):\n",
    "            \n",
    "    # if empty string is passed\n",
    "    if query=='':\n",
    "        return ''\n",
    "\n",
    "    # clean up the query\n",
    "    needed=krasavchik(query)\n",
    "\n",
    "    # strict match\n",
    "    all_features=pd.DataFrame({'words':mini_model.feature_names_in_})\n",
    "    we_have_it=all_features[all_features.words.isin(needed)].words.tolist()\n",
    "\n",
    "    # list of words that dont have a match\n",
    "    unmatched = list(set(needed)-set(we_have_it))\n",
    "    \n",
    "    # final query dtm\n",
    "    final_dataframe=pd.DataFrame(0, index=np.arange(1), columns=mini_model.feature_names_in_)\n",
    "    \n",
    "    # fuzzy match: I need to vectorize that search - may be later...\n",
    "\n",
    "    if len(unmatched)>0:\n",
    "        \n",
    "        for i in unmatched:\n",
    "\n",
    "            # list to store the distances at each iteration\n",
    "            levin=[]\n",
    "\n",
    "            # match only the one that starts with the same letter (people dont mistake their first letter)\n",
    "            if matching_by_first_letter is True:\n",
    "                # for faster perfomance\n",
    "                iteration=final_dataframe.columns[final_dataframe.columns.astype(str).str[0]==i[0]].tolist()\n",
    "            else:\n",
    "                iteration=final_dataframe.columns.tolist()\n",
    "\n",
    "            # let's iterate through all the words in the cleaned query    \n",
    "            for j in iteration:\n",
    "                dis=edit_distance(j, i, transpositions=True)\n",
    "                if dis>=distince_thresh:\n",
    "                    dis=0\n",
    "                else:\n",
    "                    #inverse of the distance - correct direction of the value\n",
    "                    dis=1/dis\n",
    "\n",
    "                levin.append(dis)\n",
    "                \n",
    "            final_dataframe[iteration]=levin\n",
    "\n",
    "    # plug in the ones we have - ths the dtm for the user query\n",
    "    final_dataframe[we_have_it]=1\n",
    "    \n",
    "    # some info on fuzzy matching \n",
    "    if show_more is True:\n",
    "\n",
    "        print('Words with perfect matching: ', we_have_it)\n",
    "        print('Words with no matching - fuzzy matching applied: ', unmatched)\n",
    "        # print(final_predictions.sort_values(by='proba', ascending=False).head(10))\n",
    "                                    \n",
    "    # we can output top 1 prediction on user query  \n",
    "    if certanty_thresh == None:\n",
    "        \n",
    "        return mini_model.predict(final_dataframe)[0]\n",
    "\n",
    "    # output all categories that fall under our \"credible region\" - recommending the best matches\n",
    "    else:\n",
    "        # df with  final predictions\n",
    "        final_predictions=pd.DataFrame({'products':mini_model.classes_.reshape(-1), \n",
    "                                        'proba':mini_model.predict_proba(final_dataframe).reshape(-1)})\n",
    "        # Credible region\n",
    "        proba_thresh = (final_predictions.proba.max())*certanty_thresh\n",
    "\n",
    "        # final list of matching products\n",
    "        at_last = final_predictions[final_predictions.proba>proba_thresh]\\\n",
    "                                            .sort_values('proba',ascending=False).products.tolist()\n",
    "\n",
    "        # if there is no good match (give the thresh the output = 50% all products in DB)\n",
    "        if len(at_last) >= round(len(final_predictions.products)/2):\n",
    "            return '''There are no good matches to your request :(\\nTry rephrazing.'''\n",
    "\n",
    "        else:\n",
    "            return at_last "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coarse dust mask', 'Fine dust mask', 'Signs tested in practice']\n"
     ]
    }
   ],
   "source": [
    "# test - write your query\n",
    "query='''dust mask'''\n",
    "\n",
    "# results\n",
    "predicted_categories = final_quering(query, certanty_thresh=0.95)\n",
    "print(predicted_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_title</th>\n",
       "      <th>manufacturers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coarse dust mask</td>\n",
       "      <td>[Dräger, Vitrex]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fine dust mask</td>\n",
       "      <td>[3M, Draper, FTUK, MoldexMetric, Precision Tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Signs tested in practice</td>\n",
       "      <td>[Brady, Eurokraft, Phoenix, Phoenix Contact, R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sub_title                                      manufacturers\n",
       "0          Coarse dust mask                                   [Dräger, Vitrex]\n",
       "1            Fine dust mask  [3M, Draper, FTUK, MoldexMetric, Precision Tec...\n",
       "2  Signs tested in practice  [Brady, Eurokraft, Phoenix, Phoenix Contact, R..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's print the manufacturers for the recomended products \n",
    "output = manufacturers[manufacturers.sub_title.isin(predicted_categories)][['sub_title',\n",
    "                                                                        'manufacturers']].reset_index(drop=True)\n",
    "\n",
    "# make sure the order is correct - according to model's predictions\n",
    "output['sort_cat'] = pd.Categorical(output['sub_title'], categories=predicted_categories, ordered=True)\n",
    "output.sort_values('sort_cat', inplace=True)\n",
    "output.reset_index(inplace=True, drop=True)\n",
    "output.drop(columns='sort_cat', inplace=True)\n",
    "\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fd276fd1bc2193d189cca7e4f9c0516854469f068cf6d6515bec58041aa833c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('python37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
